{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing and loading your data\n",
    "This tutorial introduces how SchNetPack stores and loads data.\n",
    "Before we can start training neural networks with SchNetPack, we need to prepare our data.\n",
    "This is because SchNetPack has to stream the reference data from disk during training in order to be able to handle large datasets.\n",
    "Therefore, it is crucial to use data format that allows for fast random read access.\n",
    "We found that the [ASE database format](https://wiki.fysik.dtu.dk/ase/ase/db/db.html) fulfills perfectly.\n",
    "To further improve the performance, we internally encode properties in binary.\n",
    "However, as long as you only access the ASE database via the provided SchNetPack `AtomsData` class, you don't have to worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from schnetpack import AtomsData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined datasets\n",
    "SchNetPack supports several benchmark datasets that can be used without preparation.\n",
    "Each one can be accessed using a corresponding class that inherits from `DownloadableAtomsData`, which supports automatic download and conversion. Here, we show how to use these data sets at the example of the QM9 benchmark.\n",
    "\n",
    "First, we have to import the dataset class and instantiate it. This will automatically download the data to the specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from schnetpack.datasets import QM9\n",
    "\n",
    "qm9data = QM9('./qm9.db', download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at this dataset.\n",
    "We can find out how large it is and which properties it supports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference calculations: 133885\n",
      "Available properties:\n",
      "- rotational_constant_A\n",
      "- rotational_constant_B\n",
      "- rotational_constant_C\n",
      "- dipole_moment\n",
      "- isotropic_polarizability\n",
      "- homo\n",
      "- lumo\n",
      "- gap\n",
      "- electronic_spatial_extent\n",
      "- zpve\n",
      "- energy_U0\n",
      "- energy_U\n",
      "- enthalpy_H\n",
      "- free_energy\n",
      "- heat_capacity\n"
     ]
    }
   ],
   "source": [
    "print('Number of reference calculations:', len(qm9data))\n",
    "print('Available properties:')\n",
    "\n",
    "for p in qm9data.available_properties:\n",
    "    print('-', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load data points  using zero-base indexing. The result is a dictionary containing the geometry and properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties:\n",
      "- rotational_constant_A : torch.Size([1])\n",
      "- rotational_constant_B : torch.Size([1])\n",
      "- rotational_constant_C : torch.Size([1])\n",
      "- dipole_moment : torch.Size([1])\n",
      "- isotropic_polarizability : torch.Size([1])\n",
      "- homo : torch.Size([1])\n",
      "- lumo : torch.Size([1])\n",
      "- gap : torch.Size([1])\n",
      "- electronic_spatial_extent : torch.Size([1])\n",
      "- zpve : torch.Size([1])\n",
      "- energy_U0 : torch.Size([1])\n",
      "- energy_U : torch.Size([1])\n",
      "- enthalpy_H : torch.Size([1])\n",
      "- free_energy : torch.Size([1])\n",
      "- heat_capacity : torch.Size([1])\n",
      "- _atomic_numbers : torch.Size([5])\n",
      "- _positions : torch.Size([5, 3])\n",
      "- _neighbors : torch.Size([5, 4])\n",
      "- _cell : torch.Size([3, 3])\n",
      "- _cell_offset : torch.Size([5, 4, 3])\n",
      "- _idx : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "example = qm9data[0]\n",
    "print('Properties:')\n",
    "\n",
    "for k, v in example.items():\n",
    "    print('-', k, ':', v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all available properties have been loaded as torch tensors with the given shapes. Keys with an underscore indicate that these names are reserved for internal use. This includes the geometry (`_atomic_numbers`, `_positions`, `_cell`), the index within the dataset (`_idx`) as well as information about neighboring atoms and periodic boundary conditions (`_neighbors`, `_cell_offset`). \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Note:** Neighbors are collected using an `EnvironmentProvider`, that can be passed to the `AtomsData` constructor. The default is the `SimpleEnvironmentProvider`, which constructs the neighbor list using a full distance matrix. This is suitable for small molecules. We supply environment providers using a cutoff (`AseEnvironmentProvider`, `TorchEnvironmentProvider`) that are able to handle larger molecules and periodic boundary conditions.\n",
    "</div>\n",
    "\n",
    "We can directly obtain an ASE atoms object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms object: Atoms(symbols='CH4', pbc=False)\n",
      "Atoms object (not the same): Atoms(symbols='CH4', pbc=False)\n",
      "Equivalent: True ; not the same object: False\n"
     ]
    }
   ],
   "source": [
    "at = qm9data.get_atoms(idx=0)\n",
    "print('Atoms object:', at)\n",
    "\n",
    "at2, props = qm9data.get_properties(idx=0)\n",
    "print('Atoms object (not the same):', at2)\n",
    "print('Equivalent:', at2 == at, '; not the same object:', at2 is at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, all property names are pre-defined as class-variable for convenient access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total energy at 0K: [-1101.48779008]\n",
      "HOMO: [-10.54985436]\n"
     ]
    }
   ],
   "source": [
    "print('Total energy at 0K:', props[QM9.U0])\n",
    "print('HOMO:', props[QM9.homo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your own data\n",
    "In the following we will create an ASE database from our own data.\n",
    "For this tutorial, we will use a dataset containing a molecular dynamics (MD) trajectory of ethanol, which can be downloaded [here](http://quantum-machine.org/gdml/data/xyz/ethanol_dft.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./ethanol_dft.zip'):\n",
    "    !wget http://quantum-machine.org/gdml/data/xyz/ethanol_dft.zip\n",
    "        \n",
    "if not os.path.exists('./ethanol.xyz'):\n",
    "    !unzip ./ethanol_dft.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is in xyz format with the total energy given in the comment row. For this kind of data, we supply a script that converts it into the SchNetPack ASE DB format.\n",
    "```\n",
    "spk_parse.py ./ethanol.xyz ./ethanol.db --atomic_properties Properties=species:S:1:pos:R:3:forces:R:3 --molecular_properties energy\n",
    "```\n",
    "It is generally possible to use the parsing script for other data sets, too. \n",
    "Currently the script supports **xyz** and **extended xyz** file formats (use this \n",
    "[link](https://libatoms.github.io/QUIP/io.html#extendedxyz) for further information).\n",
    "In general, both file formats consist of single or multiple time steps of some \n",
    "molecular dynamics trajectory with different atomic and/or molecular properties. One \n",
    "time step starts with the number of atoms in the first line and is followed by a \n",
    "comment line. The following lines contain the atomic properties, starting with the \n",
    "first atom of the molecule. Different properties are separated by tabs. The comment \n",
    "line differentiates between the **basic** and the **extended** file format. While \n",
    "**basic xyz** files only have unlabeled molecular properties in their comment line, \n",
    "**extended xyz** files provide the molecular properties in a dict style manner and \n",
    "also provide further information about the atomic properties via a property string. \n",
    "The property string should start with \"Properties=\" and is followed by the column \n",
    "names, data types and numbers. The default property string with atomic numbers and \n",
    "forces is `Properties=species:S:1:pos:R:3`. If your **xyz** file also contains other \n",
    "atomic properties, you need to append them to the property string with the \n",
    "``--atomic_properties <property name>:<property type>:<number of columns>``. The only\n",
    "two property types are ``S`` for **strings** and ``R`` for **numeric data types**\n",
    ". It is also possible to pass the full property string to the script. If your file \n",
    "contains molecular data, you can define the property names with \n",
    "``--molecular_properties p1 p2 ...``. If you use an **extended xyz** file, all \n",
    "information is already stored in the comment line, so the additional keywords of the \n",
    "parsing script can be ignored.\n",
    "\n",
    "In the following, we show how this can be done in general, so that you apply this to any other data format.\n",
    "\n",
    "First, we need to parse our data. For this we use the IO functionality supplied by ASE.\n",
    "In order to create a SchNetPack DB, we require a **list of ASE `Atoms` objects** as well as a corresponding **list of dictionaries** `[{property_name1: property1_molecule1}, {property_name1: property1_molecule2}, ...]` containing the mapping from property names to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy: {'-97208.40600498248': True}\n",
      "\n",
      "Properties: [{'energy': array([-97208.41], dtype=float32)}, {'energy': array([-97208.375], dtype=float32)}, {'energy': array([-97208.04], dtype=float32)}, {'energy': array([-97207.5], dtype=float32)}, {'energy': array([-97206.84], dtype=float32)}, {'energy': array([-97206.1], dtype=float32)}, {'energy': array([-97205.266], dtype=float32)}, {'energy': array([-97204.29], dtype=float32)}, {'energy': array([-97203.16], dtype=float32)}, {'energy': array([-97201.875], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "from ase.io import read\n",
    "import numpy as np\n",
    "\n",
    "# load atoms from xyz file. Here, we only parse the first 10 molecules\n",
    "atoms = read('./ethanol.xyz', index=':10')\n",
    "\n",
    "# comment line is weirdly stored in the info dictionary as key by ASE. here it corresponds to the energy\n",
    "print('Energy:', atoms[0].info)\n",
    "print()\n",
    "\n",
    "# parse properties as list of dictionaries\n",
    "property_list = []\n",
    "for at in atoms:\n",
    "    # All properties need to be stored as numpy arrays.\n",
    "    # Note: The shape for scalars should be (1,), not ()\n",
    "    # Note: GPUs work best with float32 data\n",
    "    energy = np.array([float(list(at.info.keys())[0])], dtype=np.float32)    \n",
    "    property_list.append(\n",
    "        {'energy': energy}\n",
    "    )\n",
    "    \n",
    "print('Properties:', property_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data in this format, it is straightforward to create a new SchNetPack DB and store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm './new_dataset.db'\n",
    "new_dataset = AtomsData('./new_dataset.db', available_properties=['energy'])\n",
    "new_dataset.add_systems(atoms, property_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a look at the data in the same way we did before for QM9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference calculations: 10\n",
      "Available properties:\n",
      "- energy\n",
      "\n",
      "Properties of molecule with id 0:\n",
      "- energy : torch.Size([1])\n",
      "- _atomic_numbers : torch.Size([9])\n",
      "- _positions : torch.Size([9, 3])\n",
      "- _neighbors : torch.Size([9, 8])\n",
      "- _cell : torch.Size([3, 3])\n",
      "- _cell_offset : torch.Size([9, 8, 3])\n",
      "- _idx : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print('Number of reference calculations:', len(new_dataset))\n",
    "print('Available properties:')\n",
    "\n",
    "for p in new_dataset.available_properties:\n",
    "    print('-', p)\n",
    "print()    \n",
    "\n",
    "example = new_dataset[0]\n",
    "print('Properties of molecule with id 0:')\n",
    "\n",
    "for k, v in example.items():\n",
    "    print('-', k, ':', v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same way, we can store multiple properties, including atomic properties such as forces, or tensorial properties such as polarizability tensors.\n",
    "\n",
    "In the following tutorials, we will describe how these datasets can be used to train neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Datasets\n",
    "\n",
    "For some purposes it can be necessary to merge different datasets before training a \n",
    "model. In order to allow the concatenation of datasets without changing the database \n",
    "files, we developed the `ConcatAtomsData` class. Concatenated datasets can either be \n",
    "created directly or by summation of datasets. In order to illustrate the \n",
    "concatenation of datasets, we will use `MD17` datasets of ethanol, aspirin and \n",
    "benzene. The concatenated dataset supports instances of `AtomsData`,\n",
    "`AtomsDataSubset` and `ConcatAtomsData`. Aribitrary combinations of those instances \n",
    "can be combined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from schnetpack.datasets import MD17\n",
    "ethanol = MD17(\"ethanol.db\", molecule=\"ethanol\")\n",
    "aspirin = MD17(\"aspirin.db\", molecule=\"aspirin\")\n",
    "benzene = MD17(\"benzene.db\", molecule=\"benzene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the example datasets have been created, we will create the concatenated \n",
    "dataset by initializing a new `ConcatAtomsData` instance. The single datasets can \n",
    "still be approached with the `datasets` variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_new.datasets:\n",
      "[<schnetpack.datasets.md17.MD17 object at 0x10b94b630>,\n",
      " <schnetpack.datasets.md17.MD17 object at 0x10b94ba20>,\n",
      " <schnetpack.datasets.md17.MD17 object at 0x10b82e898>]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from schnetpack.data import ConcatAtomsData\n",
    "\n",
    "concat_new = ConcatAtomsData(datasets=[ethanol, aspirin, benzene])\n",
    "print(\"concat_new.datasets:\")\n",
    "pprint(concat_new.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach to get a concatenated dataset is to use the sum operation on the \n",
    "single datasets. This yields a concatenated dataset with the same properties as the \n",
    "`concat_new` dataset, exept for the `datasets` variable. Since the three datasets are \n",
    "concatenated in two steps, the a nested structure is received. The first dataset of \n",
    "the concatenated dataset is again a concatenated dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_sum.datasets:\n",
      "[<schnetpack.data.atoms.ConcatAtomsData object at 0x10b94bf60>,\n",
      " <schnetpack.datasets.md17.MD17 object at 0x10b82e898>]\n",
      "\n",
      "\n",
      "datasets_sum.datasets[0].datasets:\n",
      "[<schnetpack.datasets.md17.MD17 object at 0x10b94b630>,\n",
      " <schnetpack.datasets.md17.MD17 object at 0x10b94ba20>]\n"
     ]
    }
   ],
   "source": [
    "concat_sum = ethanol + aspirin + benzene\n",
    "print(\"concat_sum.datasets:\")\n",
    "pprint(concat_sum.datasets)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"datasets_sum.datasets[0].datasets:\")\n",
    "pprint(concat_sum.datasets[0].datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both concatenated datasets have the same length use the same atom indexing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes of single datasets:\n",
      "- <schnetpack.datasets.md17.MD17 object at 0x10b94b630>:  555092\n",
      "- <schnetpack.datasets.md17.MD17 object at 0x10b94ba20>:  211762\n",
      "- <schnetpack.datasets.md17.MD17 object at 0x10b82e898>:  49863\n",
      "- total: 816717\n",
      "\n",
      "\n",
      "Dataset sizes of concatenated datasets:\n",
      "- <schnetpack.data.atoms.ConcatAtomsData object at 0x10b94b048>:  816717\n",
      "- <schnetpack.data.atoms.ConcatAtomsData object at 0x10b94f080>:  816717\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset sizes of single datasets:\")\n",
    "for dataset in [ethanol, aspirin, benzene]:\n",
    "    print(\"- {}: \".format(str(dataset)), len(dataset))\n",
    "print(\"- total: {}\".format(len(ethanol) + len(aspirin) + len(benzene)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Dataset sizes of concatenated datasets:\")\n",
    "for dataset in [concat_new, concat_sum]:\n",
    "    print(\"- {}: \".format(str(dataset)), len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test equality of indexing:\n",
      "- forces: True\n",
      "- energy: True\n",
      "- _atomic_numbers: True\n",
      "- _positions: True\n",
      "- _neighbors: True\n",
      "- _cell: True\n",
      "- _cell_offset: True\n",
      "- _idx: True\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "import torch\n",
    "\n",
    "idx = randint(0, len(concat_new))\n",
    "\n",
    "print(\"Test equality of indexing:\")\n",
    "for s, n, label in zip(\n",
    "        concat_sum[idx].values(), concat_new[idx].values(), concat_sum[idx].keys()\n",
    "    ):\n",
    "    print(\"- {}: {}\".format(label, torch.equal(n, s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, concatenated datasets support the property functions \n",
    "`available_properties`, `load_only` and `atomref`. Since datasets with different \n",
    "properties can also be concatenated, `load_only` and `available_properties` contain \n",
    "the intersection of the properties of the original datasets. Datasets with different \n",
    "atomic reference values will use the `atomref` property function of the first dataset. \n",
    "The loadable properties can still be changed with the use of `set_load_only`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of concatenated datasets:\n",
      "- load_only:  ['energy']\n",
      "- available_properties:  ['forces', 'energy'] \n",
      "\n",
      "Updated:\n",
      "- load_only:  ['forces', 'energy']\n",
      "- available_properties:  ['forces', 'energy']\n"
     ]
    }
   ],
   "source": [
    "ethanol = MD17(\"ethanol.db\", molecule=\"ethanol\")\n",
    "aspirin = MD17(\"aspirin.db\", molecule=\"aspirin\", load_only=[\"energy\"])\n",
    "\n",
    "concatenated = ethanol + aspirin\n",
    "\n",
    "print(\"Properties of concatenated datasets:\")\n",
    "print(\"- load_only: \", concatenated.load_only)\n",
    "print(\"- available_properties: \", concatenated.available_properties, \"\\n\")\n",
    "\n",
    "concatenated.set_load_only(concatenated.available_properties)\n",
    "\n",
    "print(\"Updated:\")\n",
    "print(\"- load_only: \", concatenated.load_only)\n",
    "print(\"- available_properties: \", concatenated.available_properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spk)",
   "language": "python",
   "name": "spk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbsphinx": {
   "execute": "never"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
